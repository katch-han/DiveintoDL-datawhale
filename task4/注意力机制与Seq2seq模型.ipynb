{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注意力机制\n",
    "在编码器—解码器（seq2seq）里，解码器在各个时间步依赖相同的背景变量来获取输入序列信息，在生成输出序列中的每一个词时可能只需利用输入序列某一部分的信息。当编码器为循环神经网络时，背景变量来自它最终时间步的隐藏状态。\n",
    "\n",
    "在seq2seq模型中，解码器只能隐式地从编码器的最终状态中选择相应的信息。然而，注意力机制可以将这种选择过程显式地建模。\n",
    "\n",
    "以循环神经网络为例，注意力机制通过对编码器所有时间步的隐藏状态做加权平均来得到背景变量。解码器在每一时间步调整这些权重，即注意力权重，从而能够在不同时间步分别关注输入序列中的不同部分并编码进相应时间步的背景变量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意力机制框架\n",
    "Attention 是一种通用的带权池化方法，输入由两部分构成：询问（query）和键值对（key-value pairs）。$𝐤_𝑖∈ℝ^{𝑑_𝑘}, 𝐯_𝑖∈ℝ^{𝑑_𝑣}$. Query  $𝐪∈ℝ^{𝑑_𝑞}$ , attention layer得到输出与value的维度一致 $𝐨∈ℝ^{𝑑_𝑣}$. 对于一个query来说，attention layer 会与每一个key计算注意力分数并进行权重的归一化，输出的向量$o$则是value的加权求和，而每个key计算的权重与value一一对应。\n",
    "\n",
    "为了计算输出，我们首先假设有一个函数$\\alpha$ 用于计算query和key的相似性，然后可以计算所有的 attention scores $a_1, \\ldots, a_n$ by\n",
    "\n",
    "\n",
    "$$\n",
    "a_i = \\alpha(\\mathbf q, \\mathbf k_i).\n",
    "$$\n",
    "\n",
    "\n",
    "我们使用 softmax函数 获得注意力权重：\n",
    "$$\n",
    "b_1, \\ldots, b_n = \\textrm{softmax}(a_1, \\ldots, a_n).\n",
    "$$\n",
    "\n",
    "\n",
    "最终的输出就是value的加权求和：\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf o = \\sum_{i=1}^n b_i \\mathbf v_i.\n",
    "$$\n",
    "\n",
    "\n",
    "<img src='attention.jpg' width=80%>\n",
    "\n",
    "不同的attetion layer的区别在于score函数的选择，两个常用的注意层是 Dot-product Attention 和 Multilayer Perceptron Attention；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 点积注意力\n",
    "The dot product 假设query和keys有相同的维度, 即 $\\forall i, 𝐪,𝐤_𝑖 ∈ ℝ_𝑑 $. 通过计算query和key转置的乘积来计算attention score,通常还会除去 $\\sqrt{d}$ 减少计算出来的score对维度𝑑的依赖性，如下\n",
    "\n",
    "\n",
    "$$\n",
    "𝛼(𝐪,𝐤)=⟨𝐪,𝐤⟩/ \\sqrt{d} \n",
    "$$\n",
    "\n",
    "假设 $ 𝐐∈ℝ^{𝑚×𝑑}$ 有 $m$ 个query，$𝐊∈ℝ^{𝑛×𝑑}$ 有 $n$ 个keys. 我们可以通过矩阵运算的方式计算所有 $mn$ 个score：\n",
    "\n",
    "\n",
    "$$\n",
    "𝛼(𝐐,𝐊)=𝐐𝐊^𝑇/\\sqrt{d}\n",
    "$$\n",
    " \n",
    "现在让我们实现这个层，它支持一批查询和键值对。此外，它支持作为正则化随机删除一些注意力权重."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层感知机注意力\n",
    "在多层感知器中，我们首先将 query and keys 投影到  $ℝ^ℎ$ .为了更具体，我们将可以学习的参数做如下映射 \n",
    "$𝐖_𝑘∈ℝ^{ℎ×𝑑_𝑘}$ ,  $𝐖_𝑞∈ℝ^{ℎ×𝑑_𝑞}$ , and  $𝐯∈ℝ^h$ . 将score函数定义\n",
    "$$\n",
    "𝛼(𝐤,𝐪)=𝐯^𝑇tanh(𝐖_𝑘𝐤+𝐖_𝑞𝐪)\n",
    "$$\n",
    ". \n",
    "然后将key 和 value 在特征的维度上合并（concatenate），然后送至 a single hidden layer perceptron 这层中 hidden layer 为  ℎ  and 输出的size为 1 .隐层激活函数为tanh，无偏置."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T02:47:53.951559Z",
     "start_time": "2020-02-17T02:47:53.938294Z"
    }
   },
   "source": [
    "### 总结\n",
    "\n",
    "- 注意力层显式地选择相关的信息。\n",
    "- 注意层的内存由键-值对组成，因此它的输出接近于键类似于查询的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入注意力机制的Seq2seq模型\n",
    "\n",
    "本节中将注意机制添加到sequence to sequence 模型中，以显式地使用权重聚合states。下图展示encoding 和decoding的模型结构，在时间步为t的时候。此刻attention layer保存着encodering看到的所有信息——即encoding的每一步输出。在decoding阶段，解码器的$t$时刻的隐藏状态被当作query，encoder的每个时间步的hidden states作为key和value进行attention聚合. Attetion model的输出当作成上下文信息context vector，并与解码器输入$D_t$拼接起来一起送到解码器：\n",
    "\n",
    "<img src='seq2seq_att1.jpg' width=80%>\n",
    "\n",
    "\n",
    "上图展示了seq2seq机制的所有层的关系，下面展示了encoder和decoder的layer结构\n",
    "\n",
    "<img src='seq2seq_att2.jpg' width=80%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码器\n",
    "   由于带有注意机制的seq2seq的编码器与之前的Seq2SeqEncoder相同，所以在此处我们只关注解码器。我们添加了一个MLP注意层(MLPAttention)，它的隐藏大小与解码器中的LSTM层相同。然后我们通过从编码器传递三个参数来初始化解码器的状态:\n",
    "   \n",
    "- the encoder outputs of all timesteps：encoder输出的各个状态，被用于attetion layer的memory部分，有相同的key和values\n",
    "\n",
    "\n",
    "- the hidden state of the encoder’s final timestep：编码器最后一个时间步的隐藏状态，被用于初始化decoder 的hidden state\n",
    "\n",
    "\n",
    "- the encoder valid length: 编码器的有效长度，借此，注意层不会考虑编码器输出中的填充标记（Paddings）\n",
    "\n",
    "\n",
    "   在解码的每个时间步，我们使用解码器的最后一个RNN层的输出作为注意层的query。然后，将注意力模型的输出与输入嵌入向量连接起来，输入到RNN层。虽然RNN层隐藏状态也包含来自解码器的历史信息，但是attention model的输出显式地选择了enc_valid_len以内的编码器输出，这样attention机制就会尽可能排除其他不相关的信息。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
