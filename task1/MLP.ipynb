{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层感知机 （multilayer perceptron, MLP)\n",
    "\n",
    "## 激活函数\n",
    "    引入激活函数，使得神经网络的全连接层不再只是对数据做仿射变换（affine transformation），通过非线性函数对隐藏变量进行变换，然后再作为下一个全连接层的输入。\n",
    "    \n",
    "### ReLU\n",
    "    ReLU（rectified linear unit）函数提供了一个很简单的非线性变换。给定元素，该函数定义为\n",
    "    ReLU(x) = max(x,0)\n",
    "\n",
    "    可以看出，ReLU函数只保留正数元素，并将负数元素清零\n",
    "   \n",
    "### Sigmoid函数\n",
    "    sigmoid函数可以将元素的值变换到0和1之间\n",
    "   $$ sigmoid(x) = \\frac{1}{1+exp(-x)} $$\n",
    "    \n",
    "### tanh函数\n",
    "    tanh（双曲正切）函数可以将元素的值变换到-1和1之间：\n",
    "   $$ tanh(x) = \\frac{1-exp(2x)}{1+exp(2x)} $$\n",
    "\n",
    "\n",
    "## 关于激活函数的选择\n",
    "ReLu函数是一个通用的激活函数，目前在大多数情况下使用。但是，ReLU函数只能在隐藏层中使用。\n",
    "\n",
    "用于分类器时，sigmoid函数及其组合通常效果更好。由于梯度消失问题，有时要避免使用sigmoid和tanh函数。\n",
    "\n",
    "在神经网络层数较多的时候，最好使用ReLu函数，ReLu函数比较简单计算量少，而sigmoid和tanh函数计算量大很多。\n",
    "\n",
    "在选择激活函数的时候可以先选用ReLu函数如果效果不理想可以尝试其他激活函数\n",
    "\n",
    "## 多层感知机\n",
    "    多层感知机就是含有至少一个隐藏层的由全连接层组成的神经网络，且每个隐藏层的输出通过激活函数进行变换。多层感知机的层数和各隐藏层中隐藏单元个数都是超参数。以单隐藏层为例并沿用本节之前定义的符号，多层感知机按以下方式计算输出\n",
    "\n",
    " $$ H = \\phi(XW_h + b_h) $$\n",
    " $$ O = OW_o + b_o $$\n",
    "\n",
    "其中，$\\phi$为激活函数\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多层感知机pytorch实现¶\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/kesci/input\")\n",
    "import d2lzh1981 as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化模型和各个参数\n",
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "    \n",
    "net = nn.Sequential(\n",
    "        d2l.FlattenLayer(),\n",
    "        nn.Linear(num_inputs, num_hiddens),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_hiddens, num_outputs), \n",
    "        )\n",
    "    \n",
    "for params in net.parameters():\n",
    "    init.normal_(params, mean=0, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "batch_size =256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size,root='/home/kesci/input/FashionMNIST2065')\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
